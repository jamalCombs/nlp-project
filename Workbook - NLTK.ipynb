{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk, string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSTIVE_WORDS_FILEPATH = \"../../data/positive-words.txt\"\n",
    "NEGATIVE_WORDS_FILEPATH = \"../../data/negative-words.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Anaylsis - NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(sentence: str) -> str:\n",
    "    return sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def tokenize_chat_data(chat_dictionary, sentence=False):\n",
    "    tokenized_chat_message_sentence = []\n",
    "    tokenized_chat_message_words = []\n",
    "    \n",
    "    for name, message in chat_dictionary.items():\n",
    "        \n",
    "        if sentence:\n",
    "            # print(\"sentences\")\n",
    "            tokenized_sentence = sent_tokenize(remove_punctuation(message))\n",
    "            tokenized_chat_message_sentence.append(tokenized_sentence)\n",
    "        \n",
    "        else:\n",
    "            # print(\"words\")\n",
    "            tokenized_words = word_tokenize(remove_punctuation(message), \"english\")\n",
    "            tokenized_chat_message_words.append(tokenized_words)\n",
    "\n",
    "\n",
    "    if sentence:\n",
    "        return tokenized_chat_message_sentence\n",
    "    \n",
    "    else:\n",
    "        return tokenized_chat_message_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_words = tokenize_chat_data(chat_data_dictionary, sentence=False)\n",
    "token_sentence = tokenize_chat_data(chat_data_dictionary, sentence=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokenized_words_list):\n",
    "    final_words = []\n",
    "\n",
    "    for index in tokenized_words_list:\n",
    "\n",
    "        for word in index:\n",
    "\n",
    "            if word not in stopwords.words('english'):\n",
    "                final_words.append(word)\n",
    "                \n",
    "    return final_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = remove_stopwords(token_words)\n",
    "cleaned_final_words_counter = Counter(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_frequency(tokenized_words_list):\n",
    "    word_frequency = []\n",
    "\n",
    "    for index in tokenized_words_list:\n",
    "        \n",
    "        for word in index:\n",
    "            word_frequency.append(word)\n",
    "            \n",
    "    \n",
    "    return word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency_words = get_word_frequency(token_words)\n",
    "fdist = FreqDist(word_frequency_words)\n",
    "fdist.most_common(30)\n",
    "fdist.plot(30, cumulative = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lexicon Normalization and Stemming\n",
    "Lemmatization - From plural to single + Base form of a word (example better-> good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(stop_word_list):\n",
    "    lemma_words = []\n",
    "\n",
    "    for word in stop_word_list:\n",
    "        lemma = WordNetLemmatizer().lemmatize(word)\n",
    "        lemma_words.append(lemma)\n",
    "        \n",
    "    return lemma_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_text = normalize_text(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyze(sentiment_text):\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(sentiment_text)\n",
    "    \n",
    "    if score['neg'] > score['pos']:\n",
    "        return(\"Negative Sentiment\")\n",
    "        \n",
    "    elif score['neg'] < score['pos']:\n",
    "        return(\"Positive Sentiment\")\n",
    "        \n",
    "    else:\n",
    "        return(\"Neutral Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_emotion_word_dataframe(chat_dict):\n",
    "    message_list = []\n",
    "    sentiment_list = []\n",
    "    name_list = []\n",
    "\n",
    "    for name, message in chat_dict.items():\n",
    "        strip_uid = name.split(\"_\")[0]\n",
    "        sentiment_list.append(sentiment_analyze(message))\n",
    "        message_list.append(message)\n",
    "        name_list.append(strip_uid)\n",
    "\n",
    "    sentiment_analysis_df = pd.DataFrame(list(zip(name_list, message_list, sentiment_list)), columns=[\"name\", \"message\", \"sentiment\"]); sentiment_analysis_df\n",
    "    \n",
    "    return sentiment_analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = generate_emotion_word_dataframe(chat_data_dictionary); sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_count_df = sentiment_df.groupby([\"sentiment\"], as_index=False).count().rename(columns={'message':'count'}).drop([\"name\"], axis=1)\n",
    "\n",
    "plt.pie(sentiment_count_df[\"count\"], \n",
    "        labels = sentiment_count_df[\"sentiment\"], \n",
    "        colors=[\"#5DADE2\", \"#3498DB\", \"#2874A6\"], \n",
    "        autopct=\"%1.1f%%\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../../data/sentiment_pie_chart.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saved Dataframes as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis_df.to_csv(\"../data/sentiment_analysis_nltk.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stored variables\n",
    "List of varibles stored using %store magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store chat_data_dictionary \n",
    "%store normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
